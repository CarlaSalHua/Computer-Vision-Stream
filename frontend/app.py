import streamlit as st
import requests
from PIL import Image
import io
import base64
import av
import os
import cv2
import numpy as np
from streamlit_webrtc import webrtc_streamer, WebRtcMode, RTCConfiguration

# 1. CONFIGURACI√ìN √öNICA DE LA P√ÅGINA (debe ser el primer comando st)
st.set_page_config(page_title="Box Detector AI", page_icon="üì¶", layout="wide")

# 2. T√çTULO PRINCIPAL DE LA APLICACI√ìN
st.title("üì¶ Detector de Cajas Llenas y Vac√≠as con IA")

# 3. URL BASE DEL BACKEND (m√°s f√°cil de mantener)
BASE_URL = os.getenv("BACKEND_URL_BASE", "http://localhost:8000")
ENDPOINT_PREDICT = f"{BASE_URL}/model/predict"
ENDPOINT_STREAM = f"{BASE_URL}/model/predict_stream"


# 4. CREACI√ìN DE PESTA√ëAS PARA CADA FUNCIONALIDAD
tab1, tab2 = st.tabs(["Procesar Imagen Est√°tica", "Detecci√≥n en Tiempo Real"])


# --- PESTA√ëA 1: L√ìGICA PARA SUBIR IM√ÅGENES ---
with tab1:
    st.header("Sube una imagen para analizar")
    imagen_subida = st.file_uploader("üì§ Elige una imagen", type=["jpg", "jpeg", "png"], key="uploader")

    col1, col2 = st.columns(2)

    with col1:
        if imagen_subida:
            st.image(imagen_subida, caption="üì∑ Imagen Original", use_container_width=True)

    if st.button("üöÄ Procesar imagen", key="process_button"):
        if imagen_subida is not None:
            try:
                with st.spinner("Procesando imagen... ‚è≥"):
                    files = {"file": (imagen_subida.name, imagen_subida.getvalue(), imagen_subida.type)}
                    response = requests.post(ENDPOINT_PREDICT, files=files)
                    
                    with col2:
                        if response.status_code == 200:
                            data = response.json()
                            img_bytes = base64.b64decode(data["image_base64"])
                            imagen_procesada = Image.open(io.BytesIO(img_bytes))
                            st.success(f"‚úÖ Objetos detectados: {data['num_objects']}")
                            st.image(imagen_procesada, caption="üì¶ Imagen Procesada", use_container_width=True)
                        else:
                            st.error(f"‚ùå Error del servidor: {response.status_code} - {response.text}")
            except requests.exceptions.RequestException as e:
                st.error(f"‚ö†Ô∏è Error de conexi√≥n con el backend: {e}")
        else:
            st.warning("Por favor, sube una imagen antes de procesar.")


# --- PESTA√ëA 2: L√ìGICA PARA DETECCI√ìN EN TIEMPO REAL ---
with tab2:
    st.header("Activa tu c√°mara para detectar en tiempo real")
    st.info("‚ÑπÔ∏è Permite el acceso a la c√°mara y presiona 'START'. Puedes usar la opci√≥n de 'Compartir Pantalla' de tu navegador si lo prefieres.")

    def video_frame_callback(frame: av.VideoFrame) -> av.VideoFrame:
    # """ Esta funci√≥n se ejecuta por cada fotograma del stream de video. """
    # Convertir el fotograma de video a una imagen que podamos usar
        img = frame.to_ndarray(format="bgr24")
        # 1. Codificar la imagen para enviarla al backend
        _, buffer = cv2.imencode('.jpg', img)
        img_base64 = base64.b64encode(buffer).decode('utf-8')

        # 2. Enviar la imagen al backend
        try:
            response = requests.post(ENDPOINT_STREAM, json={"image_base64": img_base64})
            response.raise_for_status() # Lanza un error si la respuesta no es 2xx
            data = response.json()

            # 3. Decodificar la imagen procesada recibida del backend
            img_processed_bytes = base64.b64decode(data["image_base64"])
            img_processed = cv2.imdecode(np.frombuffer(img_processed_bytes, np.uint8), cv2.IMREAD_COLOR)

            # 4. Mostrar el n√∫mero de objetos detectados sobre la imagen
            num_objects = data["num_objects"]
            text = f"Items detectados: {num_objects}"
            # Par√°metros para el texto
            font = cv2.FONT_HERSHEY_SIMPLEX
            font_scale = 1
            color = (0, 255, 0) # Verde
            thickness = 2
            text_size, _ = cv2.getTextSize(text, font, font_scale, thickness)
            text_x = 10
            text_y = text_size[1] + 10

            # Dibujar el texto en la imagen procesada
            cv2.putText(img_processed, text, (text_x, text_y), font, font_scale, color, thickness)
            
            # Devolver el fotograma procesado para mostrarlo en el frontend
            return av.VideoFrame.from_ndarray(img_processed, format="bgr24")

        except requests.exceptions.RequestException as e:
            # Si hay un error de conexi√≥n, no hacemos nada y devolvemos el frame original
            st.warning(f"No se pudo conectar al backend: {e}")
            return frame # Devuelve el frame original sin procesar

    # --- Componente de Streamlit ---
    from streamlit_webrtc import webrtc_streamer, WebRtcMode, RTCConfiguration

    # Configuraci√≥n para servidores STUN (necesario para la conexi√≥n P2P)
    RTC_CONFIGURATION = RTCConfiguration(
        {"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]}
    )

    webrtc_streamer(
        key="box-detector",
        mode=WebRtcMode.SENDRECV, # Enviar nuestro video y recibir el video procesado
        rtc_configuration=RTC_CONFIGURATION,
        video_frame_callback=video_frame_callback,
        media_stream_constraints={"video": True, "audio": False}, # Pedir acceso a video, no audio
        async_processing=True, # Procesamiento as√≠ncrono para mejor rendimiento
    )

    st.info("‚ÑπÔ∏è Puedes elegir tu c√°mara web o la opci√≥n 'Compartir Pantalla' en la ventana emergente de tu navegador.")